{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyo3xO7LZ83t"
   },
   "source": [
    "## RUL prediction using 1D CNN (FD001)\n",
    "\n",
    "In this notebook, we will use 1D CNN to predict RUL of NASA's turbofan engine dataset FD001. We will show the implementation without going into the theory of CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MC7FHKyAaZPN"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2542,
     "status": "ok",
     "timestamp": 1689144061141,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "fiRogDKYaU0l",
    "outputId": "f3319df3-8dbc-4489-8f24-61c1e9cfeba6"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/MyDrive/Cmaps.zip' -d /content/dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p-f4LgzZ83w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1689144064899,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "qhmDq6p_Z83y",
    "outputId": "e9fd2c43-1c77-41f2-8a2a-448eb6c57bfc"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4022,
     "status": "ok",
     "timestamp": 1689144700371,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "HUeAA3M8aeGS",
    "outputId": "9c204f46-62b2-484c-9fb1-0edfc5628b3c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for the flight condition\n",
    "flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Validate the user input\n",
    "while flight_condition not in ['1', '2', '3', '4']:\n",
    "    print(\"Invalid input. Please try again.\")\n",
    "    flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Set the file names based on the flight condition\n",
    "train_file = f'train_FD00{flight_condition}.txt'\n",
    "test_file = f'test_FD00{flight_condition}.txt'\n",
    "rul_file = f'RUL_FD00{flight_condition}.txt'\n",
    "\n",
    "# Load the train dataset as a dataframe\n",
    "train_dataset_path = os.path.join(train_file)\n",
    "train_data = pd.read_csv(train_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the test dataset as a dataframe\n",
    "test_dataset_path = os.path.join(test_file)\n",
    "test_data = pd.read_csv(test_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the RUL dataset as a dataframe\n",
    "rul_dataset_path = os.path.join(rul_file)\n",
    "true_rul = pd.read_csv(rul_dataset_path, delimiter='\\s+', header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hq7hqnQZ83z"
   },
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "We strongly encourage readers to go through the [dataset description and prreprocessing notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_data_description_and_preprocessing.ipynb). In that notebook we have explained how data preprocessing functions work with simple examples. In this notebook we will only use those functions. So prior familiarity with these functions is an advantage. Below are the parameters that we will use for data preprocessing:\n",
    "\n",
    "* Degradation model: Piecewise linear\n",
    "* Early RUL: 125\n",
    "* Window length: 30\n",
    "* Shift: 1\n",
    "* Data scaling: MinMaxScaling with feature range of [-1, 1]. We will **not** preform individual enginewise scaling. Rather, we will apply the scaling to the full column of training data. Why do we do that? One reason is to achieve to better result. If enginewise scaling is preformed, we achieve higher RMSE value. But if we perform, full dataset scaling, we achieve lower RMSE values (which is better).\n",
    "\n",
    "We will calculate two prediction scores on test data. In one case, we will take last 5 examples of test data for engine, calculate their predictions, and finally average those for each engine. In the second case, we will take only the last example of each engine and make predictions. The logic behind taking last 5 examples and averaging their predictions is to make the prediction robust against outliers. Due to some external factor, if our last example happens to be corrupted, its prediction outcome might be far off from the actual one. But if we average predictions from last 5 examples, we will get a more conservative estimate.\n",
    "\n",
    "In the following cell we will show boxplots of each column of training data. That will give us an idea about the values in different columns. If all the values in a column are constant, we drop those columns from our analysis.\n",
    "\n",
    "Readers can download the data from [here](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan). In the following cells, wherever data are read from a folder, readers should change the string to point to the respective folder from their system to run this notebook seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDAmk194Z831"
   },
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    \"\"\"\n",
    "    Takes datalength and earlyrul as input and\n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig_Nt6bOZ831"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets\n",
    "    from input_data and target_data.\n",
    "\n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "\n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is\n",
    "    produced as output.**\n",
    "\n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of\n",
    "               29 data points between two consecutive batches.\n",
    "\n",
    "    \"\"\"\n",
    "    num_batches = int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axx0uHlWZ832"
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins.\n",
    "\n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "\n",
    "    The function return last examples and number of last examples (a scaler) as output.\n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to\n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwWLcgpvZ832"
   },
   "source": [
    "In the following cell, we will apply `MinMaxScaling` to the full trianing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1689144726597,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "bMrPtheDZ833",
    "outputId": "26b54dad-b0c2-460a-c57d-3943b8742643"
   },
   "outputs": [],
   "source": [
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125\n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for\n",
    "# each engine is taken. If set to a different number, that many windows from last are taken.\n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5\n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped = [0,1,2,3,4,5,9,10,14,20,22,23]\n",
    "\n",
    "train_data_first_column = train_data[0]\n",
    "test_data_first_column = test_data[0]\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets,\n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "\n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        # raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "        #                      \"Try decreasing window length.\")\n",
    "        continue\n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "\n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3fhBv3VZ84F"
   },
   "source": [
    "#### Training and validation split\n",
    "\n",
    "We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689144730519,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "m-XAJ6-XZ84F",
    "outputId": "b563da1f-85ae-4846-e0c1-ab04484b0fdd"
   },
   "outputs": [],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ear8DwN3yOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def find_max_diff_np(series):\n",
    "    maxdiff = 0\n",
    "    do = True\n",
    "    adf, pvalue, usedlag, nobs, critical_values, icbest = adfuller(series, maxlag=1)\n",
    "    if pvalue < 0.05:\n",
    "        do = False\n",
    "\n",
    "    while do:\n",
    "        maxdiff += 1\n",
    "        series = np.diff(series, n=maxdiff)\n",
    "        series = series[~np.isnan(series)]  # remove NaN values resulting from differencing\n",
    "        adf, pvalue, usedlag, nobs, critical_values, icbest = adfuller(series, maxlag=1)\n",
    "        if pvalue < 0.05:  # if significant, stop differencing and testing for stationarity\n",
    "            do = False\n",
    "    return maxdiff\n",
    "\n",
    "def make_stationary_np(arr):\n",
    "    stationary_arr = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):  # for each instance/sample\n",
    "        for j in range(arr.shape[2]):  # for each feature\n",
    "            series = arr[i, :, j]\n",
    "            maxdiff = find_max_diff_np(series)\n",
    "            if maxdiff > 0:\n",
    "                series = np.diff(series, n=maxdiff)\n",
    "                series = np.pad(series, (maxdiff, 0), 'constant', constant_values=(np.nan,))\n",
    "            stationary_arr[i, :, j] = series\n",
    "    return stationary_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrza9IKh3zpc"
   },
   "outputs": [],
   "source": [
    "processed_train_data=make_stationary_np(processed_train_data)\n",
    "processed_val_data=make_stationary_np(processed_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVCLS-qHZ84G"
   },
   "source": [
    "### 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQEUeaLbqK96"
   },
   "outputs": [],
   "source": [
    "class CustomScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(CustomScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val).flatten()\n",
    "        custom_score = self.calculate_custom_score(self.y_val, y_pred)\n",
    "        print(f'Epoch {epoch+1} - Custom Score: {custom_score:.4f}')\n",
    "\n",
    "    def compute_s_score(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "        \"\"\"\n",
    "        diff = y_pred - y_true\n",
    "        return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3110,
     "status": "ok",
     "timestamp": 1689095739086,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "IJv14-bMqn4o",
    "outputId": "17373681-eba5-4ac5-c05e-afde92b3c85c"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HfrTi9_Z84G"
   },
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(256, 7, activation = \"relu\", input_shape = (window_length, processed_train_data.shape[2])),\n",
    "        layers.Conv1D(96, 7, activation = \"relu\"),\n",
    "        layers.Conv1D(32, 7, activation = \"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\",metrics=[\"mae\"], optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHd5TaWeZ84H"
   },
   "source": [
    "We will use a learning rate scheduler that will decrease the learning rate after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_CdN5B6Z84H"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHd_EoL4cvoe"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItP1N01_rIXH"
   },
   "outputs": [],
   "source": [
    "# Create Early Stopping and Reduce Learning Rate on Plateau callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP1L-_jvZ84H"
   },
   "outputs": [],
   "source": [
    "callback =[tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1), early_stopping , reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27884,
     "status": "ok",
     "timestamp": 1689145298180,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "RvCnvGihZ84H",
    "outputId": "3eeda1b9-c86a-40ad-b683-ec66c14cf4b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 25,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P45HNBScZ84I"
   },
   "source": [
    "Why did we run the model only for 30 epochs, even though the validation loss seems to be decreasing? Well, while training this model for more epochs, we previously observed that it is possible to decrease the validation loss to a very small number. But in that case, our actual test loss is not that great. This is because our model is overfitting the validation dataset. So to get a good test performance, we should stop our training at an intermediate value of the validation loss. We chose 20 epochs as that gives a good enough test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiKtSead5-wN"
   },
   "outputs": [],
   "source": [
    "model.save(\"ID_CNN_FD01.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsuV_oKgbC0S"
   },
   "source": [
    "# Results FD001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLE4l0Uo7Aue"
   },
   "outputs": [],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1689096410988,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "LroOgNS1Z84I",
    "outputId": "900c08d0-f103-495a-a842-02737dd6e596"
   },
   "outputs": [],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "true_rul= np.clip(true_rul, a_min=0, a_max=125)\n",
    "rul_pred = np.clip(rul_pred, a_min=0, a_max=125)\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)\n",
    "\n",
    "MAE = (mean_absolute_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"MAE\", MAE)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,mean_pred_for_each_engine)\n",
    "print(\"MAE   \" , MAE_perc)\n",
    "\n",
    "\n",
    "s_score = compute_s_score(true_rul, mean_pred_for_each_engine)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX9Kt2LrZ84J"
   },
   "source": [
    "We will now compute the RMSE by taking only last example of each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1689096410988,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "daLvSsNTZ84K",
    "outputId": "eef2d364-bfbf-4c2f-9c5a-e55f9318103b"
   },
   "outputs": [],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)\n",
    "MAE_new = mean_absolute_error(true_rul,preds_for_last_example)\n",
    "print(\"MAE only last examples  \" ,MAE_new)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,preds_for_last_example)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI_duDEEZ84K"
   },
   "source": [
    "If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3gVn3KXZ84K"
   },
   "source": [
    "For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n",
    "\n",
    "$$S= \\sum_{i=1}^N{s_i}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_i=\n",
    "    \\begin{cases}\n",
    "      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n",
    "      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  \n",
    "We can compute the S-metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1689096410989,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "SiyLcFHyRE1s",
    "outputId": "a40bbf63-00f2-474c-eec7-59ee2ea8b944"
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "def plot_history(fit_history):\n",
    "    output_notebook()  # Enable inline plotting in Jupyter notebooks\n",
    "    metrics = ['loss', 'mae']\n",
    "    titles = ['Loss', 'MAE']\n",
    "    plots = []\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        p = figure(title=titles[i], x_axis_label='Epochs', y_axis_label=metric)\n",
    "        p.line(fit_history.epoch, fit_history.history[metric], line_color='blue', legend_label='Train')\n",
    "        if 'val_' + metric in fit_history.history:\n",
    "            p.line(fit_history.epoch, fit_history.history['val_' + metric], line_color='red', legend_label='Validation')\n",
    "        plots.append(p)\n",
    "\n",
    "    grid = gridplot([[plots[0], plots[1]]], plot_width=1000, plot_height=800)\n",
    "    show(grid)\n",
    "\n",
    "# Assuming 'history' is your fit history data\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBetmY8nRE1s"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax.plot(series1_list, label='prediction')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax.plot(series2_list, label='true RUL')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_title('Line Plot')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1689095887946,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "Djkcxu_y385S",
    "outputId": "1bec23f8-5469-4e09-9b02-ec5569ca40e0"
   },
   "outputs": [],
   "source": [
    "plot_series( preds_for_last_example,true_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1689096413725,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "WxnctiCuRE1s",
    "outputId": "ebae639a-3400-42b9-99ef-401a5cfbc8a1"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create dataframes for each series\n",
    "    df1 = pd.DataFrame(series1_list, columns=['value'])\n",
    "    df1['type'] = 'Prediction'\n",
    "    df2 = pd.DataFrame(series2_list, columns=['value'])\n",
    "    df2['type'] = 'True RUL'\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Calculate the range of real values in the series\n",
    "    min_value = min(min(series1_list), min(series2_list))\n",
    "    max_value = max(max(series1_list), max(series2_list))\n",
    "\n",
    "    # Create a violin plot with split, specifying the range of values\n",
    "    sns.violinplot(x='type', y='value', data=df, split=True, inner='quartile', palette=\"Set2\",\n",
    "                   cut=0, scale='width', bw='silverman', width=0.8, saturation=0.8, trim=True,\n",
    "                   range=(min_value, max_value))\n",
    "\n",
    "    # Create labels\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Remaining Useful Life (RUL)')\n",
    "    plt.title(' Violin Plot of Predictions and True RUL')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_series(preds_for_last_example,true_rul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2208,
     "status": "ok",
     "timestamp": 1689096427893,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "a5bF3SzLRE1s",
    "outputId": "85ae6882-d1b8-4f0f-a69b-3e162c847b3a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "    # Use seaborn styles\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax1.plot(series1_list, label='prediction', marker='o', linestyle='-', color='b')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax1.plot(series2_list, label='true RUL', marker='o', linestyle='--', color='r')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax1.set_xlabel('Units')\n",
    "    ax1.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax1.set_title('Predicted RUL vs True Rul')\n",
    "\n",
    "    # Increase the line width\n",
    "    for line in ax1.lines:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend()\n",
    "\n",
    "    # Calculate difference between series1 and series2\n",
    "    diff = np.array(series1_list) - np.array(series2_list)\n",
    "\n",
    "    # Create a bar plot for differences\n",
    "    ax2.bar(range(len(diff)), diff, color='purple')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax2.set_xlabel('Units')\n",
    "    ax2.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax2.set_title('Difference Between Predictions and True RUL')\n",
    "\n",
    "    # Adjust space between the plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_series( preds_for_last_example,true_rul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1689095974064,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "pSb7fpsx8vTs",
    "outputId": "ba089dc6-6f0c-420c-a82b-78899c475bf5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_critical_mae(predictions, true_rul):\n",
    "    # Convert lists to numpy arrays for element-wise operations\n",
    "    predictions = np.array(predictions)\n",
    "    true_rul = np.array(true_rul)\n",
    "\n",
    "    # Find the indices where true RUL is less than 15\n",
    "    critical_indices = np.where(true_rul < 15)\n",
    "\n",
    "    # Extract the critical predictions and true RUL\n",
    "    critical_predictions = predictions[critical_indices]\n",
    "    critical_true_rul = true_rul[critical_indices]\n",
    "\n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(critical_true_rul, critical_predictions)\n",
    "\n",
    "    return mae\n",
    "mae = evaluate_critical_mae(preds_for_last_example, true_rul)\n",
    "print(f\"The MAE for critical predictions is: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXl15v9_ulx0"
   },
   "source": [
    "# RUL prediction using 1D CNN  (FD002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRhdDMXPZ84N"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We strongly encourage readers to go through the [dataset description and prreprocessing notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_data_description_and_preprocessing.ipynb). In that notebook we have explained how data preprocessing functions work with simple examples. In this notebook we will only use those functions. So prior familiarity with these functions is an advantage. Below are the parameters that we will use for data preprocessing:\n",
    "\n",
    "* Degradation model: Piecewise linear\n",
    "* Early RUL: 150\n",
    "* Window length: 20\n",
    "* Shift: 1\n",
    "* Data scaling: MinMaxScaling with feature range of [-1, 1]. We will **not** preform individual enginewise scaling. Rather, we will apply the scaling to the full column of training data. Why do we do that? One reason is to achieve to better result. If enginewise scaling is preformed, we achieve higher RMSE value. But if we perform, full dataset scaling, we achieve lower RMSE values (which is better).\n",
    "\n",
    "We will calculate two prediction scores on test data. In one case, we will take last 5 examples of test data for engine, calculate their predictions, and finally average those for each engine. In the second case, we will take only the last example of each engine and make predictions. The logic behind taking last 5 examples and averaging their predictions is to make the prediction robust against outliers. Due to some external factor, if our last example happens to be corrupted, its prediction outcome might be far off from the actual one. But if we average predictions from last 5 examples, we will get a more conservative estimate.\n",
    "\n",
    "In the following cell we will show boxplots of each column of training data. That will give us an idea about the values in different columns. If all the values in a column are constant, we drop those columns from our analysis.\n",
    "\n",
    "Readers can download the data from [here](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan). In the following cells, wherever data are read from a folder, readers should change the string to point to the respective folder from their system to run this notebook seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1689144080122,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "Xcz7uZg1u28T",
    "outputId": "87bb075d-aa49-48eb-ff8a-eb8a2a0aec3f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for the flight condition\n",
    "flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Validate the user input\n",
    "while flight_condition not in ['1', '2', '3', '4']:\n",
    "    print(\"Invalid input. Please try again.\")\n",
    "    flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Set the file names based on the flight condition\n",
    "train_file = f'train_FD00{flight_condition}.txt'\n",
    "test_file = f'test_FD00{flight_condition}.txt'\n",
    "rul_file = f'RUL_FD00{flight_condition}.txt'\n",
    "\n",
    "# Load the train dataset as a dataframe\n",
    "train_dataset_path = os.path.join('/content/dataset/CMaps', train_file)\n",
    "train_data = pd.read_csv(train_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the test dataset as a dataframe\n",
    "test_dataset_path = os.path.join('/content/dataset/CMaps', test_file)\n",
    "test_data = pd.read_csv(test_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the RUL dataset as a dataframe\n",
    "rul_dataset_path = os.path.join('/content/dataset/CMaps', rul_file)\n",
    "true_rul = pd.read_csv(rul_dataset_path, delimiter='\\s+', header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd0kx_ugZ84O"
   },
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    \"\"\"\n",
    "    Takes datalength and earlyrul as input and\n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNt3_348Z84O"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets\n",
    "    from input_data and target_data.\n",
    "\n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "\n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is\n",
    "    produced as output.**\n",
    "\n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of\n",
    "               29 data points between two consecutive batches.\n",
    "\n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUHqGGkqZ84O"
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins.\n",
    "\n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "\n",
    "    The function return last examples and number of last examples (a scaler) as output.\n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to\n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcO979s-Z84O"
   },
   "source": [
    "In the following cell, we will apply `MinMaxScaling` to the full trianing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1689144101000,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "AxSeFIEXZ84W",
    "outputId": "63c070cc-e40a-43df-be62-2be5b8bdcd09"
   },
   "outputs": [],
   "source": [
    "window_length = 20\n",
    "shift = 1\n",
    "early_rul = 150\n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for\n",
    "# each engine is taken. If set to a different number, that many windows from last are taken.\n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5\n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped = [0,1,2,3,4]\n",
    "\n",
    "train_data_first_column = train_data[0]\n",
    "test_data_first_column = test_data[0]\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets,\n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "\n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "\n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og8ec4qPZ84X"
   },
   "source": [
    "Targets vary from 0 to 192 (for example) for the engine that has a service life of 193 cycles. But in deep learning it's usually a good idea to keep numbers within a range. Below we scale targets to a range of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EasLl1FfZ84X"
   },
   "outputs": [],
   "source": [
    "target_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "processed_train_targets = target_scaler.fit_transform(processed_train_targets.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Tw_3ctAZ84Y"
   },
   "source": [
    "## Training and validation split\n",
    "\n",
    "We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1689144105614,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "QWAadgXXZ84Y",
    "outputId": "2aad0624-1461-40f9-edad-d7cdaace3d5e"
   },
   "outputs": [],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGSUuS7l1b4_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exponential_smoothing_np(arr, alpha=0.4):\n",
    "    smoothed_arr = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):  # for each instance/sample\n",
    "        for j in range(arr.shape[2]):  # for each feature\n",
    "            series = arr[i, :, j]\n",
    "            result = [series[0]]  # first value is same as series\n",
    "            for n in range(1, len(series)):\n",
    "                result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "            smoothed_arr[i, :, j] = result\n",
    "    return smoothed_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I-ey2sn1c8I"
   },
   "outputs": [],
   "source": [
    "processed_train_data=exponential_smoothing_np(processed_train_data)\n",
    "processed_val_data=exponential_smoothing_np(processed_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gViaZJ5c1uTe"
   },
   "outputs": [],
   "source": [
    "processed_test_data=exponential_smoothing_np(processed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_HXiYMNZ84Z"
   },
   "source": [
    "## 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aUso5-mZ84a"
   },
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(128, 5, activation = \"relu\", input_shape = (window_length, processed_train_data.shape[2])),\n",
    "        layers.Conv1D(96, 5, activation = \"relu\"),\n",
    "        layers.Conv1D(32, 5, activation = \"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\",metrics=\"mae\" ,  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9LtArN6Z84a"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYJ0deoIZ84b"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81577,
     "status": "ok",
     "timestamp": 1689144263966,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "drb-utzaZ84b",
    "outputId": "5b5e9db1-a56d-4df9-bf6e-1dd6146b28e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 25,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF5YW7zf42LN"
   },
   "outputs": [],
   "source": [
    "model.save('CNN_FD002.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg8-CTP7Z84b"
   },
   "source": [
    "# Results FDOO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Vkevexr-Dzi"
   },
   "source": [
    "### Last 5 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hH31HGLp2RAs"
   },
   "outputs": [],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689144339000,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "iXXDTeAqZ84d",
    "outputId": "30b23788-fe91-48be-8fa7-011e629fdf7b"
   },
   "outputs": [],
   "source": [
    "rul_pred_scaled = model.predict(processed_test_data).reshape(-1)\n",
    "rul_pred = target_scaler.inverse_transform(rul_pred_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "true_rul= np.clip(true_rul, a_min=0, a_max=150)\n",
    "rul_pred = np.clip(rul_pred, a_min=0, a_max=150)\n",
    "\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "MAE = (mean_absolute_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"MAE\", MAE)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,mean_pred_for_each_engine)\n",
    "print(\"% MAE \" , MAE_perc)\n",
    "\n",
    "s_score = compute_s_score(true_rul, mean_pred_for_each_engine)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kWXA4ghZ84e"
   },
   "source": [
    "### Last predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1689144349808,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "iNd6dnJmZ84f",
    "outputId": "d639d3e9-b072-48c7-99cf-b9e39276654c"
   },
   "outputs": [],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "\n",
    "MAE_new =  (mean_absolute_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)\n",
    "\n",
    "print(\"MAE (taking only the last examples)\", MAE_new)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,preds_for_last_example)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gc3I6K5tZ84f"
   },
   "source": [
    "If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5oe3L8bZ84g"
   },
   "source": [
    "For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n",
    "\n",
    "$$S= \\sum_{i=1}^N{s_i}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_i=\n",
    "    \\begin{cases}\n",
    "      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n",
    "      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  \n",
    "We can compute the S-metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1689100964327,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "OKjEHyW7w_G3",
    "outputId": "77b0e8bb-df5a-429d-8ff3-a98ee458ad97"
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "def plot_history(fit_history):\n",
    "    output_notebook()  # Enable inline plotting in Jupyter notebooks\n",
    "    metrics = ['loss', 'mae']\n",
    "    titles = ['Loss', 'MAE']\n",
    "    plots = []\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        p = figure(title=titles[i], x_axis_label='Epochs', y_axis_label=metric)\n",
    "        p.line(fit_history.epoch, fit_history.history[metric], line_color='blue', legend_label='Train')\n",
    "        if 'val_' + metric in fit_history.history:\n",
    "            p.line(fit_history.epoch, fit_history.history['val_' + metric], line_color='red', legend_label='Validation')\n",
    "        plots.append(p)\n",
    "\n",
    "    grid = gridplot([[plots[0], plots[1]]], plot_width=1000, plot_height=800)\n",
    "    show(grid)\n",
    "\n",
    "# Assuming 'history' is your fit history data\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1689100969043,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "-Nl87hLAw_G9",
    "outputId": "04d0726b-fd4a-4577-b744-25d702d09096"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax.plot(series1_list, label='prediction')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax.plot(series2_list, label='true RUL')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_title('Line Plot')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "plot_series(true_rul, preds_for_last_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1689100972557,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "Arydu8crw_G-",
    "outputId": "126b7953-cb73-46a4-8655-06ed9ee9feff"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create dataframes for each series\n",
    "    df1 = pd.DataFrame(series1_list, columns=['value'])\n",
    "    df1['type'] = 'Prediction'\n",
    "    df2 = pd.DataFrame(series2_list, columns=['value'])\n",
    "    df2['type'] = 'True RUL'\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Calculate the range of real values in the series\n",
    "    min_value = min(min(series1_list), min(series2_list))\n",
    "    max_value = max(max(series1_list), max(series2_list))\n",
    "\n",
    "    # Create a violin plot with split, specifying the range of values\n",
    "    sns.violinplot(x='type', y='value', data=df, split=True, inner='quartile', palette=\"Set2\",\n",
    "                   cut=0, scale='width', bw='silverman', width=0.8, saturation=0.8, trim=True,\n",
    "                   range=(min_value, max_value))\n",
    "\n",
    "    # Create labels\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Remaining Useful Life (RUL)')\n",
    "    plt.title(' Violin Plot of Predictions and True RUL')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1762,
     "status": "ok",
     "timestamp": 1689100989491,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "JxWTSrKPw_G-",
    "outputId": "9d99dd44-b1d1-4178-d5d2-dca3f0c146bd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "    # Use seaborn styles\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax1.plot(series1_list, label='prediction', marker='o', linestyle='-', color='b')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax1.plot(series2_list, label='true RUL', marker='o', linestyle='--', color='r')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax1.set_xlabel('Units')\n",
    "    ax1.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax1.set_title('Predicted RUL vs True Rul')\n",
    "\n",
    "    # Increase the line width\n",
    "    for line in ax1.lines:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend()\n",
    "\n",
    "    # Calculate difference between series1 and series2\n",
    "    diff = np.array(series1_list) - np.array(series2_list)\n",
    "\n",
    "    # Create a bar plot for differences\n",
    "    ax2.bar(range(len(diff)), diff, color='purple')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax2.set_xlabel('Units')\n",
    "    ax2.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax2.set_title('Difference Between Predictions and True RUL')\n",
    "\n",
    "    # Adjust space between the plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnwK08ZEZ84h"
   },
   "source": [
    "It is very likely that readers may get sligtly different results while running this notebook on their system. This happens because of the nondeterministic nature of some deep learning operations and dependence of libraries like `Tensorflow` on computer architecture. Therefore, to make our results reproducible, we also share saved models of all our notebooks. All saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/tree/master/saved_models/cmapss). A notebook describing the procedure to use the saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_using_saved_model_1D_CNN_FD002.ipynb). As a final note remember that hyperparameter tuning is more of an art than science. It is possible to obtain better results than what has been obtained here by choosing better set of hyperparameters.\n",
    "\n",
    "For other reproducible results on RUL, interested readers can visit my [project page](https://biswajitsahoo1111.github.io/rul_codes_open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1689101004915,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "v7TN63UG8jTk",
    "outputId": "31b8c518-8c25-4ebc-994a-94e5ef8c9142"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_critical_mae(predictions, true_rul):\n",
    "    # Convert lists to numpy arrays for element-wise operations\n",
    "    predictions = np.array(predictions)\n",
    "    true_rul = np.array(true_rul)\n",
    "\n",
    "    # Find the indices where true RUL is less than 15\n",
    "    critical_indices = np.where(true_rul < 15)\n",
    "\n",
    "    # Extract the critical predictions and true RUL\n",
    "    critical_predictions = predictions[critical_indices]\n",
    "    critical_true_rul = true_rul[critical_indices]\n",
    "\n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(critical_true_rul, critical_predictions)\n",
    "\n",
    "    return mae\n",
    "mae = evaluate_critical_mae(preds_for_last_example, true_rul)\n",
    "print(f\"The MAE for critical predictions is: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN_ulBJSZ84i"
   },
   "source": [
    "# RUL prediction using 1D CNN (FD003)\n",
    "\n",
    "In this notebook, we will use 1D CNN to predict RUL of NASA's turbofan engine dataset FD003. We will show the implementation without going into the theory of CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2649,
     "status": "ok",
     "timestamp": 1689096462976,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "7uXR5K_3xjsE",
    "outputId": "edf5940a-dc20-4298-e4f2-c43b9924ab3e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for the flight condition\n",
    "flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Validate the user input\n",
    "while flight_condition not in ['1', '2', '3', '4']:\n",
    "    print(\"Invalid input. Please try again.\")\n",
    "    flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Set the file names based on the flight condition\n",
    "train_file = f'train_FD00{flight_condition}.txt'\n",
    "test_file = f'test_FD00{flight_condition}.txt'\n",
    "rul_file = f'RUL_FD00{flight_condition}.txt'\n",
    "\n",
    "# Load the train dataset as a dataframe\n",
    "train_dataset_path = os.path.join('/content/dataset/CMaps', train_file)\n",
    "train_data = pd.read_csv(train_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the test dataset as a dataframe\n",
    "test_dataset_path = os.path.join('/content/dataset/CMaps', test_file)\n",
    "test_data = pd.read_csv(test_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the RUL dataset as a dataframe\n",
    "rul_dataset_path = os.path.join('/content/dataset/CMaps', rul_file)\n",
    "true_rul = pd.read_csv(rul_dataset_path, delimiter='\\s+', header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJ8ULyMGZ84i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689096469598,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "tDJ52-jnZ84i",
    "outputId": "f57c3792-ca44-4924-b14d-a827a333cfc9"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQGBhQb7Z84i"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We strongly encourage readers to go through the [dataset description and prreprocessing notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_data_description_and_preprocessing.ipynb). In that notebook we have explained how data preprocessing functions work with simple examples. In this notebook we will only use those functions. So prior familiarity with these functions is an advantage. Below are the parameters that we will use for data preprocessing:\n",
    "\n",
    "* Degradation model: Piecewise linear\n",
    "* Early RUL: 125\n",
    "* Window length: 30\n",
    "* Shift: 1\n",
    "* Data scaling: MinMaxScaling with feature range of [-1, 1]. We will **not** preform individual enginewise scaling. Rather, we will apply the scaling to the full column of training data. Why do we do that? One reason is to achieve to better result. If enginewise scaling is preformed, we achieve higher RMSE value. But if we perform, full dataset scaling, we achieve lower RMSE values (which is better).\n",
    "\n",
    "We will calculate two prediction scores on test data. In one case, we will take last 5 examples of test data for engine, calculate their predictions, and finally average those for each engine. In the second case, we will take only the last example of each engine and make predictions. The logic behind taking last 5 examples and averaging their predictions is to make the prediction robust against outliers. Due to some external factor, if our last example happens to be corrupted, its prediction outcome might be far off from the actual one. But if we average predictions from last 5 examples, we will get a more conservative estimate.\n",
    "\n",
    "In the following cell we will show boxplots of each column of training data. That will give us an idea about the values in different columns. If all the values in a column are constant, we drop those columns from our analysis.\n",
    "\n",
    "Readers can download the data from [here](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan). In the following cells, wherever data are read from a folder, readers should change the string to point to the respective folder from their system to run this notebook seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbXJSLCKZ84j"
   },
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    \"\"\"\n",
    "    Takes datalength and earlyrul as input and\n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsLoU4NhZ84l"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets\n",
    "    from input_data and target_data.\n",
    "\n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "\n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is\n",
    "    produced as output.**\n",
    "\n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of\n",
    "               29 data points between two consecutive batches.\n",
    "\n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XF8lv7TDZ84l"
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins.\n",
    "\n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "\n",
    "    The function return last examples and number of last examples (a scaler) as output.\n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to\n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnHnkp1AZ84l"
   },
   "source": [
    "In the following cell, we will apply `MinMaxScaling` to the full trianing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1689096476182,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "BwLNHClAZ84m",
    "outputId": "4d0851e9-aab7-4c31-a078-0f783f1a8a0b"
   },
   "outputs": [],
   "source": [
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125\n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for\n",
    "# each engine is taken. If set to a different number, that many windows from last are taken.\n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5\n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "valid_indices=[]\n",
    "\n",
    "columns_to_be_dropped = [0,1,2,3,4,5,9,14,20,22,23]\n",
    "\n",
    "train_data_first_column = train_data[0]\n",
    "test_data_first_column = test_data[0]\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets,\n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "\n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        # raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                            #  \"Try decreasing window length.\")\n",
    "        continue\n",
    "\n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "\n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "    valid_indices.append(i-1)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "true_rul = true_rul[valid_indices]\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Vuc0HvFZ84n"
   },
   "source": [
    "## Training and validation split\n",
    "\n",
    "We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689096479257,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "1A5EfUm4Z84n",
    "outputId": "4637de7b-c0f9-4ac4-b9a1-d910394fbed0"
   },
   "outputs": [],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w4xVWsaZ84n"
   },
   "source": [
    "## 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1iqhUtlZ84o"
   },
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(256, 7, activation = \"relu\", input_shape = (window_length, processed_train_data.shape[2])),\n",
    "        layers.Conv1D(96, 7, activation = \"relu\"),\n",
    "        layers.Conv1D(32, 7, activation = \"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\",metrics=\"mae\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXCHCBo-Z84o"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfTj7UcuZ84o"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31807,
     "status": "ok",
     "timestamp": 1689096516037,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "rjo-aQrVZ84o",
    "outputId": "3796f62b-aa69-4cd9-c796-da711858a43e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 20,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FN0BK9j_wEq"
   },
   "outputs": [],
   "source": [
    "model.save(\"FD003_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Egry6RikZ84p"
   },
   "source": [
    "Why did we run the model only for 20 epochs, even though the validation loss seems to be decreasing? Well, while training this model for more epochs, we previously observed that it is possible to decrease the validation loss to a very small number. But in that case, our actual test loss is not that great. This is because our model is overfitting the validation dataset. So to get a good test performance, we should stop our training at an intermediate value of the validation loss. We chose 10 epochs as that gives a good enough test error. It has been empirically obaserved (for this case) that we get good test loss when validation loss is close to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA5OwJlvyczc"
   },
   "source": [
    "# Results FD003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1689097411221,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "3vcOnZ9yZ84p",
    "outputId": "517889fe-5cca-4140-a683-0e5ff2e086aa"
   },
   "outputs": [],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "\n",
    "true_rul= np.clip(true_rul, a_min=0, a_max=125)\n",
    "rul_pred = np.clip(rul_pred, a_min=0, a_max=125)\n",
    "\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)\n",
    "\n",
    "MAE = (mean_absolute_error(true_rul, mean_pred_for_each_engine))\n",
    "\n",
    "print(\"MAE\", MAE)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,mean_pred_for_each_engine)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "\n",
    "s_score = compute_s_score(true_rul, mean_pred_for_each_engine)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpjAIVxOZ84q"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"FD003_1D_CNN_piecewise_RMSE_\"+ str(np.round(RMSE, 4)) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62LIKEm6Z84q"
   },
   "source": [
    "We will now compute the RMSE by taking only last example of each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689097417042,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "jOLfVp3wZ84q",
    "outputId": "1332623a-e73e-4f5f-ae97-fce9a40fe657"
   },
   "outputs": [],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)\n",
    "\n",
    "MAE_new = mean_absolute_error(true_rul,preds_for_last_example)\n",
    "print(\"MAE (taking only the last example):\", MAE_new)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,preds_for_last_example)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "\n",
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfJBIePkZ84q"
   },
   "source": [
    "If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ6IW7aSZ84s"
   },
   "source": [
    "For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n",
    "\n",
    "$$S= \\sum_{i=1}^N{s_i}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_i=\n",
    "    \\begin{cases}\n",
    "      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n",
    "      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  \n",
    "We can compute the S-metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1689097447525,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "F1F3Wxy9ylMR",
    "outputId": "b0feabae-cdac-4efe-b38c-8aea96abc287"
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "def plot_history(fit_history):\n",
    "    output_notebook()  # Enable inline plotting in Jupyter notebooks\n",
    "    metrics = ['loss', 'mae']\n",
    "    titles = ['Loss', 'MAE']\n",
    "    plots = []\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        p = figure(title=titles[i], x_axis_label='Epochs', y_axis_label=metric)\n",
    "        p.line(fit_history.epoch, fit_history.history[metric], line_color='blue', legend_label='Train')\n",
    "        if 'val_' + metric in fit_history.history:\n",
    "            p.line(fit_history.epoch, fit_history.history['val_' + metric], line_color='red', legend_label='Validation')\n",
    "        plots.append(p)\n",
    "\n",
    "    grid = gridplot([[plots[0], plots[1]]], plot_width=1200, plot_height=800)\n",
    "    show(grid)\n",
    "\n",
    "# Assuming 'history' is your fit history data\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1802,
     "status": "ok",
     "timestamp": 1689097457114,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "2jq26MiUylMR",
    "outputId": "9a1cb123-4be0-4ca3-8c6e-0ebe5dad53d4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax.plot(series1_list, label='prediction')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax.plot(series2_list, label='true RUL')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_title('Line Plot')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "plot_series(true_rul, preds_for_last_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1689097468482,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "nmAcnbNlylMR",
    "outputId": "13a5d003-c045-49cb-ced9-cc11111eed39"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create dataframes for each series\n",
    "    df1 = pd.DataFrame(series1_list, columns=['value'])\n",
    "    df1['type'] = 'Prediction'\n",
    "    df2 = pd.DataFrame(series2_list, columns=['value'])\n",
    "    df2['type'] = 'True RUL'\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Calculate the range of real values in the series\n",
    "    min_value = min(min(series1_list), min(series2_list))\n",
    "    max_value = max(max(series1_list), max(series2_list))\n",
    "\n",
    "    # Create a violin plot with split, specifying the range of values\n",
    "    sns.violinplot(x='type', y='value', data=df, split=True, inner='quartile', palette=\"Set2\",\n",
    "                   cut=0, scale='width', bw='silverman', width=0.8, saturation=0.8, trim=True,\n",
    "                   range=(min_value, max_value))\n",
    "\n",
    "    # Create labels\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Remaining Useful Life (RUL)')\n",
    "    plt.title(' Violin Plot of Predictions and True RUL')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1689097505868,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "9WT9elx9ylMS",
    "outputId": "85320141-aa86-43da-a838-8ea5063f2563"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "    # Use seaborn styles\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax1.plot(series1_list, label='prediction', marker='o', linestyle='-', color='b')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax1.plot(series2_list, label='true RUL', marker='o', linestyle='--', color='r')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax1.set_xlabel('Units')\n",
    "    ax1.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax1.set_title('Predicted RUL vs True Rul')\n",
    "\n",
    "    # Increase the line width\n",
    "    for line in ax1.lines:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend()\n",
    "\n",
    "    # Calculate difference between series1 and series2\n",
    "    diff = np.array(series1_list) - np.array(series2_list)\n",
    "\n",
    "    # Create a bar plot for differences\n",
    "    ax2.bar(range(len(diff)), diff, color='purple')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax2.set_xlabel('Units')\n",
    "    ax2.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax2.set_title('Difference Between Predictions and True RUL')\n",
    "\n",
    "    # Adjust space between the plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rSYkcxDZ84w"
   },
   "source": [
    "It is very likely that readers may get sligtly different results while running this notebook on their system. This happens because of the nondeterministic nature of some deep learning operations and dependence of libraries like `Tensorflow` on computer architecture. Therefore, to make our results reproducible, we also share saved models of all our notebooks. All saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/tree/master/saved_models/cmapss). A notebook describing the procedure to use the saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_using_saved_model_deep_learning.ipynb). As a final note remember that hyperparameter tuning is more of an art than science. It is possible to obtain better results than what has been obtained here by choosing better set of hyperparameters.\n",
    "\n",
    "For other reproducible results on RUL, interested readers can visit my [project page](https://biswajitsahoo1111.github.io/rul_codes_open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1689097511711,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "oIVRW_P48m7Y",
    "outputId": "8cd4506a-2813-4857-e167-fe597d838f7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_critical_mae(predictions, true_rul):\n",
    "    # Convert lists to numpy arrays for element-wise operations\n",
    "    predictions = np.array(predictions)\n",
    "    true_rul = np.array(true_rul)\n",
    "\n",
    "    # Find the indices where true RUL is less than 15\n",
    "    critical_indices = np.where(true_rul < 15)\n",
    "\n",
    "    # Extract the critical predictions and true RUL\n",
    "    critical_predictions = predictions[critical_indices]\n",
    "    critical_true_rul = true_rul[critical_indices]\n",
    "\n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(critical_true_rul, critical_predictions)\n",
    "\n",
    "    return mae\n",
    "mae = evaluate_critical_mae(preds_for_last_example, true_rul)\n",
    "print(f\"The MAE for critical predictions is: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "li0DOEgDZ84w"
   },
   "source": [
    "# RUL prediction using 1D CNN (FD004)\n",
    "\n",
    "In this notebook, we will use 1D CNN to predict RUL of NASA's turbofan engine dataset FD004. We will show the implementation without going into the theory of CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xd9K0PjAZ84w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689097530145,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "dU830fS5Z84w",
    "outputId": "1eb7ec86-8435-4774-8a85-ef86ae074897"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2126,
     "status": "ok",
     "timestamp": 1689145471060,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "t8wB1NUXyyw8",
    "outputId": "70aaaa6e-4cab-4393-d5e2-247626b44a1d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for the flight condition\n",
    "flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Validate the user input\n",
    "while flight_condition not in ['1', '2', '3', '4']:\n",
    "    print(\"Invalid input. Please try again.\")\n",
    "    flight_condition = input(\"Please enter the flight condition (1-4): \")\n",
    "\n",
    "# Set the file names based on the flight condition\n",
    "train_file = f'train_FD00{flight_condition}.txt'\n",
    "test_file = f'test_FD00{flight_condition}.txt'\n",
    "rul_file = f'RUL_FD00{flight_condition}.txt'\n",
    "\n",
    "# Load the train dataset as a dataframe\n",
    "train_dataset_path = os.path.join('/content/dataset/CMaps', train_file)\n",
    "train_data = pd.read_csv(train_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the test dataset as a dataframe\n",
    "test_dataset_path = os.path.join('/content/dataset/CMaps', test_file)\n",
    "test_data = pd.read_csv(test_dataset_path, delimiter='\\s+', header=None)\n",
    "\n",
    "# Load the RUL dataset as a dataframe\n",
    "rul_dataset_path = os.path.join('/content/dataset/CMaps', rul_file)\n",
    "true_rul = pd.read_csv(rul_dataset_path, delimiter='\\s+', header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS84RgCHZ84x"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We strongly encourage readers to go through the [dataset description and prreprocessing notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_data_description_and_preprocessing.ipynb). In that notebook we have explained how data preprocessing functions work with simple examples. In this notebook we will only use those functions. So prior familiarity with these functions is an advantage. Below are the parameters that we will use for data preprocessing:\n",
    "\n",
    "* Degradation model: Piecewise linear\n",
    "* Early RUL: 150\n",
    "* Window length: 15\n",
    "* Shift: 1\n",
    "* Data scaling: MinMaxScaling with feature range of [-1, 1]. We will **not** preform individual enginewise scaling. Rather, we will apply the scaling to the full column of training data. Why do we do that? One reason is to achieve to better result. If enginewise scaling is preformed, we achieve higher RMSE value. But if we perform, full dataset scaling, we achieve lower RMSE values (which is better).\n",
    "\n",
    "We will calculate two prediction scores on test data. In one case, we will take last 5 examples of test data for engine, calculate their predictions, and finally average those for each engine. In the second case, we will take only the last example of each engine and make predictions. The logic behind taking last 5 examples and averaging their predictions is to make the prediction robust against outliers. Due to some external factor, if our last example happens to be corrupted, its prediction outcome might be far off from the actual one. But if we average predictions from last 5 examples, we will get a more conservative estimate.\n",
    "\n",
    "In the following cell we will show boxplots of each column of training data. That will give us an idea about the values in different columns. If all the values in a column are constant, we drop those columns from our analysis.\n",
    "\n",
    "Readers can download the data from [here](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan). In the following cells, wherever data are read from a folder, readers should change the string to point to the respective folder from their system to run this notebook seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4aVtlnaZ84y"
   },
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    \"\"\"\n",
    "    Takes datalength and earlyrul as input and\n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UOIdb5mZ84y"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets\n",
    "    from input_data and target_data.\n",
    "\n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "\n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is\n",
    "    produced as output.**\n",
    "\n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of\n",
    "               29 data points between two consecutive batches.\n",
    "\n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0LtlwdrZ84z"
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins.\n",
    "\n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "\n",
    "    The function return last examples and number of last examples (a scaler) as output.\n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to\n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ope9mBTvZ84z"
   },
   "source": [
    "In the following cell, we will apply `MinMaxScaling` to the full trianing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1689145479353,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "0D-zx_YlZ84z",
    "outputId": "502d1c84-ca87-41ac-ed9c-9b745fc24f9e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "window_length = 15\n",
    "shift = 1\n",
    "early_rul = 150\n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for\n",
    "# each engine is taken. If set to a different number, that many windows from last are taken.\n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5\n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped = [0,1,2,3,4]\n",
    "\n",
    "train_data_first_column = train_data[0]\n",
    "test_data_first_column = test_data[0]\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets,\n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "\n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "\n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "\n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LdI1lDzZ840"
   },
   "source": [
    "Targets vary from 0 to 192 (for example) for the engine that has a service life of 193 cycles. But in deep learning it's usually a good idea to keep numbers within a range. Below we scale targets to a range of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9kAxhaCZ840"
   },
   "outputs": [],
   "source": [
    "target_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "processed_train_targets = target_scaler.fit_transform(processed_train_targets.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZayZoDkZ840"
   },
   "source": [
    "## Training and validation split\n",
    "\n",
    "We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689145483280,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "BK7no4O6Z840",
    "outputId": "89bb9941-587d-4ba8-c231-9177cb3e5823"
   },
   "outputs": [],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8-k2DMR6qOL"
   },
   "outputs": [],
   "source": [
    "processed_train_data=exponential_smoothing_np(processed_train_data)\n",
    "processed_val_data=exponential_smoothing_np(processed_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZI-3hfOZ841"
   },
   "source": [
    "## 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI44zpn7Z841"
   },
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(512, 3, activation = \"relu\", input_shape = (window_length, processed_train_data.shape[2])),\n",
    "        layers.Conv1D(96, 5, activation = \"relu\"),\n",
    "        layers.Conv1D(32, 5, activation = \"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\",metrics=\"mae\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCwb4H3PZ841"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 20:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6oV2zd9Z842"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143416,
     "status": "ok",
     "timestamp": 1689145643702,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "Iph7UcPRZ842",
    "outputId": "e6713f13-e177-4eca-f70a-ad46c8d29801",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 25,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWzfPlj7Z842"
   },
   "source": [
    "# Results FD004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1689145645200,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "apAqaha6Z842",
    "outputId": "228323a0-8bec-4c41-c8a8-62db20b46733"
   },
   "outputs": [],
   "source": [
    "rul_pred_scaled = model.predict(processed_test_data).reshape(-1)\n",
    "rul_pred = target_scaler.inverse_transform(rul_pred_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "true_rul= np.clip(true_rul, a_min=0, a_max=150)\n",
    "rul_pred = np.clip(rul_pred, a_min=0, a_max=150)\n",
    "\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)\n",
    "\n",
    "MAE = (mean_absolute_error(true_rul, mean_pred_for_each_engine))\n",
    "\n",
    "print(\"MAE\", MAE)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,mean_pred_for_each_engine)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "\n",
    "s_score = compute_s_score(true_rul, mean_pred_for_each_engine)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZ4HWgEOZ843"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"FD004_1D_CNN_piecewise_RMSE_\"+ str(np.round(RMSE, 4)) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2otT7J5nZ843"
   },
   "source": [
    "We will now compute the RMSE by taking only last example of each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1689101128022,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "YP_9j8McZ844",
    "outputId": "78d6eb79-50e2-4dbe-84fa-ada43c263890"
   },
   "outputs": [],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)\n",
    "\n",
    "MAE_new = mean_absolute_error(true_rul,preds_for_last_example)\n",
    "print(\"RMSE (Taking only last examples): \",MAE_new)\n",
    "\n",
    "MAE_perc= mean_absolute_percentage_error(true_rul,preds_for_last_example)\n",
    "print(\"% MAE only last examples  \" , MAE_perc)\n",
    "\n",
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PoPfde7Z844"
   },
   "source": [
    "If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nm252G0WZ844"
   },
   "source": [
    "For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n",
    "\n",
    "$$S= \\sum_{i=1}^N{s_i}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_i=\n",
    "    \\begin{cases}\n",
    "      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n",
    "      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  \n",
    "We can compute the S-metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1689101128022,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "lVSwzvY6z1Gy",
    "outputId": "56a3c928-cab4-4bbe-fe48-d3ea41d60f13"
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "def plot_history(fit_history):\n",
    "    output_notebook()  # Enable inline plotting in Jupyter notebooks\n",
    "    metrics = ['loss', 'mae']\n",
    "    titles = ['Loss', 'MAE']\n",
    "    plots = []\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        p = figure(title=titles[i], x_axis_label='Epochs', y_axis_label=metric)\n",
    "        p.line(fit_history.epoch, fit_history.history[metric], line_color='blue', legend_label='Train')\n",
    "        if 'val_' + metric in fit_history.history:\n",
    "            p.line(fit_history.epoch, fit_history.history['val_' + metric], line_color='red', legend_label='Validation')\n",
    "        plots.append(p)\n",
    "\n",
    "    grid = gridplot([[plots[0], plots[1]]], plot_width=1200, plot_height=800)\n",
    "    show(grid)\n",
    "\n",
    "# Assuming 'history' is your fit history data\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1689101128957,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "CSegggEKz1Gy",
    "outputId": "0d9b7650-d7bd-4a08-fe2d-4fb100778b60"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax.plot(series1_list, label='prediction')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax.plot(series2_list, label='true RUL')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_title('Line Plot')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "plot_series(true_rul, preds_for_last_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689101128958,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "yqtI4YNQz1Gz",
    "outputId": "433f6a05-86ac-44a2-c7f5-ca87614fc523"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create dataframes for each series\n",
    "    df1 = pd.DataFrame(series1_list, columns=['value'])\n",
    "    df1['type'] = 'Prediction'\n",
    "    df2 = pd.DataFrame(series2_list, columns=['value'])\n",
    "    df2['type'] = 'True RUL'\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Calculate the range of real values in the series\n",
    "    min_value = min(min(series1_list), min(series2_list))\n",
    "    max_value = max(max(series1_list), max(series2_list))\n",
    "\n",
    "    # Create a violin plot with split, specifying the range of values\n",
    "    sns.violinplot(x='type', y='value', data=df, split=True, inner='quartile', palette=\"Set2\",\n",
    "                   cut=0, scale='width', bw='silverman', width=0.8, saturation=0.8, trim=True,\n",
    "                   range=(min_value, max_value))\n",
    "\n",
    "    # Create labels\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Remaining Useful Life (RUL)')\n",
    "    plt.title(' Violin Plot of Predictions and True RUL')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1689101130238,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "rGK0kOVBz1Gz",
    "outputId": "8165d18d-7d5f-44b1-b226-c4501150b1ce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_series(series1, series2):\n",
    "    # Convert series to lists\n",
    "    series1_list = series1.tolist()\n",
    "    series2_list = series2.tolist()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14,12))\n",
    "\n",
    "    # Use seaborn styles\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plot series1 as a line plot\n",
    "    ax1.plot(series1_list, label='prediction', marker='o', linestyle='-', color='b')\n",
    "\n",
    "    # Plot series2 as a line plot\n",
    "    ax1.plot(series2_list, label='true RUL', marker='o', linestyle='--', color='r')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax1.set_xlabel('Units')\n",
    "    ax1.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax1.set_title('Predicted RUL vs True Rul')\n",
    "\n",
    "    # Increase the line width\n",
    "    for line in ax1.lines:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend()\n",
    "\n",
    "    # Calculate difference between series1 and series2\n",
    "    diff = np.array(series1_list) - np.array(series2_list)\n",
    "\n",
    "    # Create a bar plot for differences\n",
    "    ax2.bar(range(len(diff)), diff, color='purple')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax2.set_xlabel('Units')\n",
    "    ax2.set_ylabel('Remaining Useful Life (RUL)')\n",
    "    ax2.set_title('Difference Between Predictions and True RUL')\n",
    "\n",
    "    # Adjust space between the plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_series(true_rul, preds_for_last_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689101130238,
     "user": {
      "displayName": "Alberto Moccardi",
      "userId": "09120262365331070077"
     },
     "user_tz": -120
    },
    "id": "8le5EvmG8r62",
    "outputId": "f7311535-3e66-4ba0-d3c1-ab16f4789533"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_critical_mae(predictions, true_rul):\n",
    "    # Convert lists to numpy arrays for element-wise operations\n",
    "    predictions = np.array(predictions)\n",
    "    true_rul = np.array(true_rul)\n",
    "\n",
    "    # Find the indices where true RUL is less than 15\n",
    "    critical_indices = np.where(true_rul < 15)\n",
    "\n",
    "    # Extract the critical predictions and true RUL\n",
    "    critical_predictions = predictions[critical_indices]\n",
    "    critical_true_rul = true_rul[critical_indices]\n",
    "\n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(critical_true_rul, critical_predictions)\n",
    "\n",
    "    return mae\n",
    "mae = evaluate_critical_mae(preds_for_last_example, true_rul)\n",
    "print(f\"The MAE for critical predictions is: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtR6nAUFE6ST"
   },
   "outputs": [],
   "source": [
    "model.save(\"FD004_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxH63gAn9sNv"
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHie5JYTbCS5"
   },
   "source": [
    "1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vly7DimYATbT"
   },
   "source": [
    "Last prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYTCM79C9uah"
   },
   "source": [
    "| Dataset | RMSE   | MAE    | % MAE  | S-score   |\n",
    "|---------|--------|--------|--------|-----------|\n",
    "| FD001   | 16.309 | 12.200 | 0.195  | 790.498   |\n",
    "| FD002   | 14.881 | 10.865 | 0.160  | 547.131   |\n",
    "| FD003   | 31.585 | 23.200 | 0.439  | 57331.120 |\n",
    "| FD004   | 32.646 | 25.048 | 0.464  | 206951.236 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz1vOEezAV-d"
   },
   "source": [
    "Last 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIjOcpgpAZz-"
   },
   "source": [
    "| Dataset | RMSE   | MAE    | % MAE  | S-score   |\n",
    "|---------|--------|--------|--------|-----------|\n",
    "| FD001   | 16.097 | 12.221 | 0.176  | 437.483   |\n",
    "| FD002   | 14.881 | 10.865 | 0.160  | 42300.407 |\n",
    "| FD003   | 31.585 | 23.200 | 0.439  | 63957.260 |\n",
    "| FD004   | 32.433 | 23.502 | 0.400  | 42300.407 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHevQWy7bENR"
   },
   "source": [
    "LSTM"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eN_ulBJSZ84i",
    "iA5OwJlvyczc"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1u5OK1q7TwoFiQlw-2BRPEYDtomODNiMX",
     "timestamp": 1699389387344
    }
   ]
  },
  "interpreter": {
   "hash": "510e49bc31fb65b0d041977739a3e5f5edf9f8cd04bc034d427b5346da960650"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
